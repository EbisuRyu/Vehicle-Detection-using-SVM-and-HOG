{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script.model_localization import pyramid, sliding_window, iou_bbox, non_maximum_supperssion, visualize_bbox\n",
    "from script.model_classification import SVMObjectClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from script.dataset import load_vehicle_dataset, load_traffic_signboard_dataset_test\n",
    "from script.feature_source import FeatureExtracter\n",
    "from script.training import training_model\n",
    "from script.slider import Slider\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\" Compute the Intersection over Union (IoU) of two bounding boxes. \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    # Compute the coordinates of the intersection rectangle\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    inter_area = max(0, xi2 - xi1 + 1) * max(0, yi2 - yi1 + 1)\n",
    "\n",
    "    # Compute the area of both the prediction and ground-truth rectangles\n",
    "    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    box2_area = (x2g - x1g + 1) * (y2g - y1g + 1)\n",
    "\n",
    "    # Compute the intersection over union by taking the intersection area\n",
    "    # and dividing it by the sum of prediction + ground-truth areas - inter_area\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "def evaluate_detection(pred_boxes, pred_labels, gt_boxes, gt_labels, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate precision and recall for object detection.\n",
    "\n",
    "    Args:\n",
    "        pred_boxes (list of list): Predicted bounding boxes [x1, y1, x2, y2].\n",
    "        pred_labels (list): Predicted labels.\n",
    "        gt_boxes (list of list): Ground truth bounding boxes [x1, y1, x2, y2].\n",
    "        gt_labels (list): Ground truth labels.\n",
    "        iou_threshold (float): IoU threshold to consider a valid detection.\n",
    "\n",
    "    Returns:\n",
    "        precision (float), recall (float)\n",
    "    \"\"\"\n",
    "    assert len(pred_boxes) == len(pred_labels)\n",
    "    assert len(gt_boxes) == len(gt_labels)\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    detected_gt = [False] * len(gt_boxes)\n",
    "\n",
    "    for pred_box, pred_label in zip(pred_boxes, pred_labels):\n",
    "        match_found = False\n",
    "        for i, (gt_box, gt_label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "            if pred_label == gt_label and iou(pred_box, gt_box) >= iou_threshold:\n",
    "                if not detected_gt[i]:\n",
    "                    TP += 1\n",
    "                    detected_gt[i] = True\n",
    "                    match_found = True\n",
    "                    break\n",
    "        if not match_found:\n",
    "            FP += 1\n",
    "\n",
    "    FN = detected_gt.count(False)\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "sourcer_params = {             \n",
    "  'spatial_size': (32, 32), # (16, 16), (32, 32), (64, 64)\n",
    "  'orientations': 9,        # 6 - 12\n",
    "  'pixels_per_cell': 8,     # 8, 16\n",
    "  'cells_per_block': 2,     # 1, 2\n",
    "  'transform_sqrt': True,\n",
    "  'block_norm': 'L2',\n",
    "  'hog_visualize': False\n",
    "}\n",
    "exist_path = './save_model/model.pkl'\n",
    "save_path = './save_model'\n",
    "feature_extracter = FeatureExtracter(**sourcer_params)\n",
    "model = SVMObjectClassifier(C=0.3)\n",
    "model.set_feature_extracter(feature_extracter)\n",
    "if os.path.exists(save_path + '/model.pkl'):\n",
    "    print('Loading model...')\n",
    "    model.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "images, labels, bounding_boxes = load_traffic_signboard_dataset_test()\n",
    "\n",
    "index_range = list(range(len(images)))\n",
    "random_index = random.sample(index_range, 50)\n",
    "\n",
    "gt_boxes = []\n",
    "gt_labels = []\n",
    "test_images = []\n",
    "for index in random_index:\n",
    "    test_images.append(images[index])\n",
    "    gt_boxes.append(bounding_boxes[index])\n",
    "    gt_labels.append(labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:34<00:00, 13.89s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pred_boxes = []\n",
    "pred_labels = []\n",
    "\n",
    "for image in tqdm(test_images):\n",
    "    pred_box = []\n",
    "    pred_label = []\n",
    "    windowSize = [(20, 20), (40, 40), (60, 60), (100, 100)]\n",
    "    image_path = './dataset/traffic_sign_board/images/road106.png'\n",
    "    #cv2.imread(image_path)\n",
    "    predict_bbox = []\n",
    "    for window_size in windowSize:\n",
    "        slider = Slider(model, window_size, 5, scale=1.75, visualize=False)\n",
    "        predict_bbox += slider.predict(image, 0.995)\n",
    "    predict_bbox = non_maximum_supperssion(predict_bbox, 0.2)\n",
    "    pred_boxes.append([box[:4] for box in predict_bbox])\n",
    "    pred_labels.append([box[4] for box in predict_bbox])\n",
    "    #visualize_bbox(image, predict_bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.5633333333333334, Average Recall: 0.5733333333333333, F1 Score: 0.5682893450635386\n"
     ]
    }
   ],
   "source": [
    "'''# Example usage:\n",
    "pred_boxes = [[50, 50, 100, 100], [30, 30, 60, 60]]\n",
    "pred_labels = ['cat', 'dog']\n",
    "gt_boxes = [[48, 48, 98, 98], [29, 29, 58, 58]]\n",
    "gt_labels = ['cat', 'dog']'''\n",
    "\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "#print(pred_boxes, pred_labels)\n",
    "#print(gt_boxes, gt_labels)\n",
    "for pred_box, pred_label, gt_box, gt_label in zip(pred_boxes, pred_labels, gt_boxes, gt_labels):  \n",
    "    precision, recall = evaluate_detection(pred_box, pred_label, gt_box, gt_label)\n",
    "    #print(f\"Precision: {precision}, Recall: {recall}\")\n",
    "    sum_precision += precision\n",
    "    sum_recall += recall\n",
    "average_precision = sum_precision / len(pred_boxes)\n",
    "average_recall = sum_recall / len(pred_boxes)\n",
    "f1_score = 2 * average_precision * average_recall / (average_precision + average_recall)\n",
    "print(f\"Average Precision: {average_precision}, Average Recall: {average_recall}, F1 Score: {f1_score}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "dataset_dir = './dataset/traffic_sign_board'\n",
    "image_dir = os.path.join(dataset_dir, 'images')\n",
    "annotation_dir = os.path.join(dataset_dir, 'annotations')\n",
    "\n",
    "file_path = os.path.join(annotation_dir, 'road0.xml')\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "image_file = root.find('filename').text\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "img = cv2.imread(image_path)\n",
    "image_label = []\n",
    "bounding_box = []\n",
    "adding = False\n",
    "label = None\n",
    "for object in root.findall('object'):\n",
    "    label = object.find('name').text\n",
    "    if label == 'trafficlight':\n",
    "        continue\n",
    "    xmin = int(object.find('bndbox/xmin').text)\n",
    "    ymin = int(object.find('bndbox/ymin').text)\n",
    "    xmax = int(object.find('bndbox/xmax').text)\n",
    "    ymax = int(object.find('bndbox/ymax').text)\n",
    "    bounding_box.append([xmin, ymin, xmax, ymax])\n",
    "    image_label.append(label)\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
