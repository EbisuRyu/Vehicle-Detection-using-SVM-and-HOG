{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np \n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from script.helpers import convert, show_images, put_boxes, box_boundaries\n",
    "from script.feature_source import FeatureExtracter\n",
    "from script.model_classification import SVMObjectClassifier\n",
    "from script.helpers import show_images\n",
    "from script.slider import Slider\n",
    "from script.heatmap import HeatMap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import moviepy\n",
    "moviepy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_to_rgb(data):\n",
    "    data_ = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    my_cmap = plt.get_cmap('hot')\n",
    "    img = my_cmap(data_)\n",
    "    rgb_img = np.dstack((img[:, :, 0], img[:, :, 1], img[:, :, 2]))\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVMObjectClassifier()\n",
    "model.load('./save_model')\n",
    "\n",
    "sourcer_params = {             # hls, hsv, yuv, ycrcb,\n",
    "  'spatial_size': (32, 32),            # (16, 16), (32, 32), (64, 64)\n",
    "  'orientations': 9,        # 6 - 12\n",
    "  'pixels_per_cell': 8,               # 8, 16\n",
    "  'cells_per_block': 2,                # 1, 2\n",
    "  'transform_sqrt': True,\n",
    "  'block_norm': 'L2',\n",
    "  'hog_visualize': False\n",
    "}\n",
    "feature_extracter = FeatureExtracter(**sourcer_params)\n",
    "model.set_feature_extracter(feature_extracter)\n",
    "slider = Slider(model, None, 20, scale=1.5, strip_position=None, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imresize(image, fraction):\n",
    "    return cv2.resize(image, (int(image.shape[1] * fraction), int(image.shape[0] * fraction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_frame = cv2.imread('./test_images/test1.jpg')\n",
    "heatmap = HeatMap(frame = temp_frame, thresh = 5, memory = 30)\n",
    "def verbose_pipeline(this_frame, view_process = False):\n",
    "  windowSizes = [(80, 80), (100, 100), (120, 120)]\n",
    "  strip_positions = [(410, 600), (400, 600), (400, 600)]\n",
    "  for window_size, strip_position in zip(windowSizes, strip_positions):\n",
    "    slider.update_strip_position(strip_position)\n",
    "    slider.update_window_size(window_size)\n",
    "    bounding_boxes = slider.predict(this_frame, 0.7)\n",
    "    heatmap.update(bounding_boxes)\n",
    "    if view_process:\n",
    "      print(bounding_boxes)\n",
    "  \n",
    "  mp, _, _ = heatmap.get()\n",
    "  labeled_img = heatmap.draw(this_frame)\n",
    "  rgb_img = imresize(hot_to_rgb(mp), 0.25)\n",
    "  labeled_img[20:20 + rgb_img.shape[0], 20:20 + rgb_img.shape[1]] = rgb_img * 200\n",
    "  if view_process:\n",
    "    show_images([rgb_img, labeled_img], 1, 2, W=15, H=7)\n",
    "  return labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_frame = cv2.imread('./test_images/test1.jpg')\n",
    "heatmap = HeatMap(frame = temp_frame, thresh = 5, memory = 30)\n",
    "def verbose_pipeline(this_frame, view_process = False):\n",
    "  windowSizes = [(80, 80), (100, 100), (120, 120)]\n",
    "  #strip_positions = [(410, 600), (400, 600), (400, 600)]\n",
    "  for window_size in windowSizes:\n",
    "    slider.update_window_size(window_size)\n",
    "    bounding_boxes = slider.predict(this_frame, 0.92)\n",
    "    heatmap.update(bounding_boxes)\n",
    "    if view_process:\n",
    "      print(bounding_boxes)\n",
    "  \n",
    "  mp, _, _ = heatmap.get()\n",
    "  labeled_img = heatmap.draw(this_frame)\n",
    "  rgb_img = imresize(hot_to_rgb(mp), 0.25)\n",
    "  labeled_img[20:20 + rgb_img.shape[0], 20:20 + rgb_img.shape[1]] = rgb_img * 200\n",
    "  if view_process:\n",
    "    show_images([rgb_img, labeled_img], 1, 2, W=15, H=7)\n",
    "  return labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_video_output.mp4.\n",
      "Moviepy - Writing video test_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_video_output.mp4\n",
      "CPU times: total: 2min 28s\n",
      "Wall time: 2min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1060\" height=\"640\" controls>\n",
       "  <source src=\"test_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_output = 'test_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"./traffic-sign-test.mp4\")\n",
    "white_clip = clip1.fl_image(verbose_pipeline) \n",
    "%time white_clip.write_videofile(project_output, audio = False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"1060\" height=\"640\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
